export CUDA_DEVICE_MAX_CONNECTIONS=1
export NCCL_DEBUG=WARN
export NCCL_SOCKET_IFNAME=eth0

GPUS_PER_NODE=${GPU_PER_NODE_COUNT:=8}
NUM_NODES=${AZUREML_NODE_COUNT:=1}
NODE_RANK=${NODE_RANK:=0}
MASTER_ADDR=${MASTER_ADDR:=localhost}
MASTER_PORT=${MASTER_PORT:=1828}
WORLD_SIZE=$(($GPUS_PER_NODE*$NUM_NODES))

FORCE_TORCHRUN=1 \
NNODES=${NUM_NODES} \
NODE_RANK=${NODE_RANK} \
MASTER_ADDR=${MASTER_ADDR} \
MASTER_PORT=${MASTER_PORT} \
llamafactory-cli train examples/sigma_17A3B_train.yaml
